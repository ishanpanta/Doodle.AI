# Doodle.AI

## Doodle Recognition

**Model Architecture**

![LRCN drawio](https://github.com/ishanpanta/Doodle.AI/assets/62653942/56d40101-2287-4d33-b9e8-359503a5127e)
                                                              _Figure: LRCN Model_

**LRCN**, or Long-term Recurrent Convolutional Network, is a hybrid model that combines the power of Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). It is designed to process sequential data, such as videos or time series data, by incorporating both spatial and temporal information.

The key idea behind LRCN is to leverage the strengths of CNNs in capturing spatial features from individual frames and the strengths of RNNs in modeling temporal 
dependencies across frames. This allows the model to learn both short-term and long-term dependencies in sequential data.

## Doodle Generation

**Model Architecture**

![gans_doodle](https://github.com/ishanpanta/Doodle.AI/assets/62653942/48e8caa1-f35e-4077-8389-2d0118288a41)
                                                              _Figure: GANs Model_

**Generator:**
The generator component of the Generative Adversarial Network (GAN) model utilizes a Long Short-Term Memory (LSTM) network with 96 units. Each unit in the LSTM network outputs a pair of x and y coordinates. Importantly, the time coordinate value for each unit depends on the coordinates generated by the previous unit, enabling the sequence to unfold over time.

**Discriminator**
The discriminator component within the Generative Adversarial Network (GAN) model employs a Long-Short Term Memory Recurrent Convolutional Network (LRCN) model to discern between real and fake doodles. LRCN, being a combination of LSTM (Long Short-Term Memory) and CNN (Convolutional Neural Network) architectures, is adept at processing sequential data like doodle strokes while also capturing spatial features. This enables the discriminator to effectively analyze the strokes of doodles.
